{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lat Long Analysis\n",
    "\n",
    "This portion of our project uses the schools' latitude and longitude (previously obtained using geocoder) to perform some final cleaning on the VADIR data and then join it to the NYC crime data by location. The code below will:  \n",
    "\n",
    "* __Load vadir data__ and cleaning it with the functions from cleandata.py  \n",
    "* Ensure __schools are consistently named__ (we'll use the names from the lat long file and join them using the beds/seds code. This also means that we'll discard records from the schools for which we don't have lat/long)  \n",
    "* __Fill in missing boroughs__ for records from 2006-2007.  \n",
    "* __Identify felonies within a 1 mile__ radius of a given school.  \n",
    "* __Plot correlations__ between school indicents and felonies (by year, by borough, by felony type, by location, by school incident type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import vincenty\n",
    "import cleandata as cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and clean the VADIR data from the 2006-2014 school years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... data from VADIR_2006.xls appended. Added 1455 rows for a total of 1455.\n",
      "... data from VADIR_2007.xls appended. Added 1500 rows for a total of 2955.\n",
      "... data from VADIR_2008.xls appended. Added 1545 rows for a total of 4500.\n",
      "... data from VADIR_2009.xls appended. Added 1531 rows for a total of 6031.\n",
      "... data from VADIR_2010.xls appended. Added 1678 rows for a total of 7709.\n",
      "... data from VADIR_2011.xls appended. Added 1693 rows for a total of 9402.\n",
      "... data from VADIR_2012.xls appended. Added 1735 rows for a total of 11137.\n",
      "... data from VADIR_2013.xls appended. Added 1792 rows for a total of 12929.\n",
      "... data from VADIR_2014.xls appended. Added 1805 rows for a total of 14734.\n"
     ]
    }
   ],
   "source": [
    "# Raw data for each year\n",
    "RAW_DATA_DICT = {2006: 'VADIR_2006.xls', 2007: 'VADIR_2007.xls', 2008: 'VADIR_2008.xls', \n",
    "                 2009: 'VADIR_2009.xls', 2010: 'VADIR_2010.xls', 2011: 'VADIR_2011.xls', \n",
    "                 2012: 'VADIR_2012.xls', 2013: 'VADIR_2013.xls', 2014: 'VADIR_2014.xls'}\n",
    "\n",
    "# Duplicate name columns in raw files (and their replacements)\n",
    "DUP_COLS = {'County Name':'County', 'District Name': 'District', 'BEDS CODE': 'BEDS Code', \n",
    "            'False Alarm':'Bomb Threat False Alarm',\n",
    "            'Other Sex offenses': 'Other Sex Offenses', \n",
    "            'Use Possession or Sale of Drugs': 'Drug Possession', \n",
    "            'Use Possession or Sale of Alcohol': 'Alcohol Possession',\n",
    "            'Other Disruptive Incidents': 'Other Disruptive Incidents', \n",
    "            'Drug Possesion': 'Drug Possession', 'Alcohol Possesion': 'Alcohol Possession', \n",
    "            'Other Disruptive': 'Other Disruptive Incidents'}\n",
    "\n",
    "# Read in raw data and correct duplicate columns\n",
    "vadir_df = cd.vadir_concat_dfs(RAW_DATA_DICT, DUP_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reorder columns putting demographic information first.\n",
    "DEMO_COLS = ['School Name', 'School Type', 'School Year', 'BEDS Code',  'County', \n",
    "             'District', 'Enrollment', 'Grade Organization', 'Need/Resource Category']\n",
    "vadir_df = cd.vadir_reorder_columns(vadir_df, DEMO_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Columns for \"Total incidents\", \"Incidents w/out Weapons\" and \"Incidents w/ Weapons\"\n",
    "COLUMNS = vadir_df.columns.tolist()\n",
    "INCIDENT_COLS = [c for c in COLUMNS if c not in DEMO_COLS]\n",
    "vadir_df = cd.vadir_create_tallies(vadir_df, INCIDENT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning VADIR data...\n",
    "# ... consistently name county and school type, fix name capitalization, remove comment rows.\n",
    "school_df = cd.vadir_clean_concat_df(vadir_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look\n",
    "school_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Join School Data and Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in lat-long file that contains correct names and locations\n",
    "#... ??? replace this call with function call to geocoder ???\n",
    "latlon_df = pd.read_csv('SchoolLatLon.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a look\n",
    "latlon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensure BEDS and SED are integers so that they'll be recognized as identical\n",
    "latlon_df[\"SED CODE\"] = latlon_df[\"SED CODE\"].astype(np.int64)\n",
    "school_df[\"BEDS Code\"] = school_df[\"BEDS Code\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join latlong data to school data using the BEDS code\n",
    "school_df = pd.merge(school_df, latlon_df, left_on=['BEDS Code'],right_on=['SED CODE'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the now redundant SED code\n",
    "school_df.drop(['SED CODE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 1967 unique schools,\n",
      "... of which 1807 have lat/long\n",
      "... and 160 are missing lat/long\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the resulting data/missing values\n",
    "print('... {} unique schools,'.format(len(school_df['BEDS Code'].unique())))\n",
    "schools_withloc = school_df[school_df['latlon'].notnull()]['BEDS Code'].unique()\n",
    "schools_missingloc = school_df[school_df['latlon'].isnull()]['BEDS Code'].unique()\n",
    "print('... of which {} have lat/long'.format(len(schools_withloc)))\n",
    "print('... and {} are missing lat/long'.format(len(schools_missingloc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix School Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... original dataset has 3135 unique school names.\n",
      "... but only 1967 unique BEDS Codes.\n"
     ]
    }
   ],
   "source": [
    "# The problem:\n",
    "print('... original dataset has {} unique school names'.format(len(school_df['School Name'].unique())))\n",
    "print('... but only {} unique BEDS Codes'.format(len(school_df['BEDS Code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def fix_case(x):\n",
    "    \"\"\"Function to put a school name in the correct case\"\"\"\n",
    "    if not x:\n",
    "        return x\n",
    "    elif x[:3] in ['PS ', 'JHS', 'MS ']:\n",
    "        return x[:3] + x[3:].title()\n",
    "    else:\n",
    "        return x.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix missing LEGAL NAMES with School Name\n",
    "school_df['LEGAL NAME'].fillna(school_df['School Name'], inplace=True)\n",
    "\n",
    "# Fix case and reassign to School Name\n",
    "school_df['School Name'] = school_df['LEGAL NAME'].apply(fix_case)\n",
    "\n",
    "# drop the now redundant LEGAL NAME column\n",
    "school_df.drop(['LEGAL NAME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... new dataset has 1959 unique school names.\n",
      "... and 1967 unique BEDS Codes.\n"
     ]
    }
   ],
   "source": [
    "# Problem Solved\n",
    "print('... new dataset has {} unique school names.'.format(len(school_df['School Name'].unique())))\n",
    "print('... and {} unique BEDS Codes.'.format(len(school_df['BEDS Code'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing boroughs\n",
    "\n",
    "... It turns out this was assigned to Svetlana so I'm going to pause on this item until we talk tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many BEDS Codes are linked with more than one Borough(County)?\n",
    "#school_df.groupby('BEDS Code')['County'].apply(lambda x: len(x.unique())).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lets look at one of these 'multi county schools'\n",
    "#school_df.groupby('BEDS Code')['County'].apply(lambda x: len(x.unique())).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#school_df[school_df['BEDS Code'] == 307500011035]['County'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each row with nan in borough, id borough of same beds code in another year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to identify crimes with in a mile of a school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function  \n",
    "def is_in_radius(school_point, crime_point, radius):\n",
    "    \"\"\"\n",
    "    Function using vincenty package to check distance between school and crime.\n",
    "    INPUT: (lat,long) tuples for school and crime (in degrees), radius in miles.\n",
    "    OUTPUT: Boolean\n",
    "    \"\"\"\n",
    "    return vincenty(school_point, crime_point, miles=True) <= radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load NYC dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fxn to tally specified types of crimes w/in radius of school\n",
    "# ... looping is going to be super inefficient, find a way to do this with DP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
