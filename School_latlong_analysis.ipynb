{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lat Long Analysis\n",
    "\n",
    "This portion of our project uses the schools' latitude and longitude (previously obtained using geocoder) to perform some final cleaning on the VADIR data and then join it to the NYC crime data by location. The code below will:  \n",
    "\n",
    "* __Load vadir data__ and cleaning it with the functions from cleandata.py  \n",
    "* Ensure __schools are consistently named__ (we'll use the names from the lat long file and join them using the beds/seds code. This also means that we'll discard records from the schools for which we don't have lat/long)  \n",
    "* __Fill in missing boroughs__ for records from 2006-2007.  \n",
    "* __Identify felonies within a 1 mile__ radius of a given school.  \n",
    "* __Plot correlations__ between school indicents and felonies (by year, by borough, by felony type, by location, by school incident type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from vincenty import vincenty\n",
    "import cleandata as cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and clean the VADIR data from the 2006-2014 school years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... data from VADIR_2006.xls appended. Added 1455 rows for a total of 1455.\n",
      "... data from VADIR_2007.xls appended. Added 1500 rows for a total of 2955.\n",
      "... data from VADIR_2008.xls appended. Added 1545 rows for a total of 4500.\n",
      "... data from VADIR_2009.xls appended. Added 1531 rows for a total of 6031.\n",
      "... data from VADIR_2010.xls appended. Added 1678 rows for a total of 7709.\n",
      "... data from VADIR_2011.xls appended. Added 1693 rows for a total of 9402.\n",
      "... data from VADIR_2012.xls appended. Added 1735 rows for a total of 11137.\n",
      "... data from VADIR_2013.xls appended. Added 1792 rows for a total of 12929.\n",
      "... data from VADIR_2014.xls appended. Added 1805 rows for a total of 14734.\n"
     ]
    }
   ],
   "source": [
    "# Raw data for each year\n",
    "RAW_DATA_DICT = {2006: 'VADIR_2006.xls', 2007: 'VADIR_2007.xls', 2008: 'VADIR_2008.xls', \n",
    "                 2009: 'VADIR_2009.xls', 2010: 'VADIR_2010.xls', 2011: 'VADIR_2011.xls', \n",
    "                 2012: 'VADIR_2012.xls', 2013: 'VADIR_2013.xls', 2014: 'VADIR_2014.xls'}\n",
    "\n",
    "# Duplicate name columns in raw files (and their replacements)\n",
    "DUP_COLS = {'County Name':'County', 'District Name': 'District', 'BEDS CODE': 'BEDS Code', \n",
    "            'False Alarm':'Bomb Threat False Alarm',\n",
    "            'Other Sex offenses': 'Other Sex Offenses', \n",
    "            'Use Possession or Sale of Drugs': 'Drug Possession', \n",
    "            'Use Possession or Sale of Alcohol': 'Alcohol Possession',\n",
    "            'Other Disruptive Incidents': 'Other Disruptive Incidents', \n",
    "            'Drug Possesion': 'Drug Possession', 'Alcohol Possesion': 'Alcohol Possession', \n",
    "            'Other Disruptive': 'Other Disruptive Incidents'}\n",
    "\n",
    "# Read in raw data and correct duplicate columns\n",
    "vadir_df = cd.vadir_concat_dfs(RAW_DATA_DICT, DUP_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reorder columns putting demographic information first.\n",
    "DEMO_COLS = ['School Name', 'School Type', 'School Year', 'BEDS Code',  'County', \n",
    "             'District', 'Enrollment', 'Grade Organization', 'Need/Resource Category']\n",
    "vadir_df = cd.vadir_reorder_columns(vadir_df, DEMO_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Columns for \"Total incidents\", \"Incidents w/out Weapons\" and \"Incidents w/ Weapons\"\n",
    "COLUMNS = vadir_df.columns.tolist()\n",
    "INCIDENT_COLS = [c for c in COLUMNS if c not in DEMO_COLS]\n",
    "vadir_df = cd.vadir_create_tallies(vadir_df, INCIDENT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning VADIR data...\n",
    "# ... consistently name county and school type, fix name capitalization, remove comment rows.\n",
    "school_df = cd.vadir_clean_concat_df(vadir_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look\n",
    "school_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Join School Data and Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in lat-long file that contains correct names and locations\n",
    "#... ??? replace this call with function call to geocoder ???\n",
    "latlon_df = pd.read_csv('SchoolLatLon.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take a look\n",
    "latlon_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ensure BEDS and SED are integers so that they'll be recognized as identical\n",
    "latlon_df[\"SED CODE\"] = latlon_df[\"SED CODE\"].astype(np.int64)\n",
    "school_df[\"BEDS Code\"] = school_df[\"BEDS Code\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join latlong data to school data using the BEDS code\n",
    "school_df = pd.merge(school_df, latlon_df, left_on=['BEDS Code'],right_on=['SED CODE'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop the now redundant SED code\n",
    "school_df.drop(['SED CODE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 1967 unique schools,\n",
      "... of which 1807 have lat/long\n",
      "... and 160 are missing lat/long\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the resulting data/missing values\n",
    "print('... {} unique schools,'.format(len(school_df['BEDS Code'].unique())))\n",
    "schools_withloc = school_df[school_df['latlon'].notnull()]['BEDS Code'].unique()\n",
    "schools_missingloc = school_df[school_df['latlon'].isnull()]['BEDS Code'].unique()\n",
    "print('... of which {} have lat/long'.format(len(schools_withloc)))\n",
    "print('... and {} are missing lat/long'.format(len(schools_missingloc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix School Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... original dataset has 3135 unique school names\n",
      "... but only 1967 unique BEDS Codes\n"
     ]
    }
   ],
   "source": [
    "# The problem:\n",
    "print('... original dataset has {} unique school names'.format(len(school_df['School Name'].unique())))\n",
    "print('... but only {} unique BEDS Codes'.format(len(school_df['BEDS Code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def fix_case(x):\n",
    "    \"\"\"Function to put a school name in the correct case\"\"\"\n",
    "    if not x:\n",
    "        return x\n",
    "    elif x[:3] in ['PS ', 'JHS', 'MS ']:\n",
    "        return x[:3] + x[3:].title()\n",
    "    else:\n",
    "        return x.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix missing LEGAL NAMES with School Name\n",
    "school_df['LEGAL NAME'].fillna(school_df['School Name'], inplace=True)\n",
    "\n",
    "# Fix case and reassign to School Name\n",
    "school_df['School Name'] = school_df['LEGAL NAME'].apply(fix_case)\n",
    "\n",
    "# drop the now redundant LEGAL NAME column\n",
    "school_df.drop(['LEGAL NAME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... new dataset has 1959 unique school names.\n",
      "... and 1967 unique BEDS Codes.\n"
     ]
    }
   ],
   "source": [
    "# Problem Solved\n",
    "print('... new dataset has {} unique school names.'.format(len(school_df['School Name'].unique())))\n",
    "print('... and {} unique BEDS Codes.'.format(len(school_df['BEDS Code'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing boroughs\n",
    "\n",
    "__TODO:__ From the numbers below it looks like some of the County values got switched around (eg. decrease in Manhattan counts?)... I think we probalby need a way of creating the county_map dictionary that prioritizes the traditional borough name). Come back to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... 3076 entries are missing county info\n",
      "Other county tallies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Brooklyn              3566\n",
       "Bronx                 2737\n",
       "Queens                2260\n",
       "Manhattan             1228\n",
       "New York              1040\n",
       "Staten Island          478\n",
       "Nyc Central Office     344\n",
       "Nassau                   1\n",
       "Name: County, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first problem:\n",
    "print('... {} entries are missing county info'.format(sum(school_df['County'].isnull())))\n",
    "print('Other county tallies:')\n",
    "school_df.County.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dictionary of county by BEDS Code\n",
    "c = school_df[school_df['County'].notnull()][['BEDS Code','County']].to_dict()\n",
    "county_map = {c['BEDS Code'][idx]: c['County'][idx] for idx in c['County'].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map counties using dictionary\n",
    "school_df.County = school_df['BEDS Code'].map(county_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Now only 3 entries are missing county info\n",
      "Other county tallies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Brooklyn              4637\n",
       "Bronx                 3536\n",
       "Queens                2961\n",
       "New York              2856\n",
       "Staten Island          639\n",
       "Manhattan               80\n",
       "Nyc Central Office       9\n",
       "Nassau                   9\n",
       "Name: County, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first problem Solved\n",
    "print('... Now only {} entries are missing county info'.format(sum(school_df['County'].isnull())))\n",
    "print('Other county tallies:')\n",
    "school_df.County.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1967\n",
       "Name: County, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are any BEDS Codes are linked with more than one Borough(County)?\n",
    "school_df.groupby('BEDS Code')['County'].apply(lambda x: len(x.unique())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep for distance sorting crime locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function -- check dist\n",
    "def is_in_radius(school_point, crime_point, radius):\n",
    "    \"\"\"\n",
    "    Function using vincenty package to check distance between school and crime.\n",
    "    INPUT: (lat,long) tuples for school and crime (in degrees), radius in miles.\n",
    "    OUTPUT: Boolean\n",
    "    \"\"\"\n",
    "    return vincenty(school_point, crime_point, miles=True) <= radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function -- extract lat/long from object type\n",
    "def parse_latlong(dataframe, loc_column):\n",
    "    \"\"\"\n",
    "    Function to extract lat/long coords. \n",
    "    INPUT: dataframe and name of column with string tuple or list pair of coordinates.\n",
    "    OUTPUT: n/a. Function modifies dataframe to add a lat and long column with float type.\n",
    "    \"\"\"\n",
    "    get_lat = lambda x: x.split(',')[0][1:] if type(x)==type('s') else np.nan\n",
    "    get_long = lambda x: x.split(',')[1][:-1] if type(x)==type('s') else np.nan\n",
    "    dataframe['lat'] = dataframe[loc_column].apply(get_lat).astype('float64')\n",
    "    dataframe['long'] = dataframe[loc_column].apply(get_long).astype('float64')\n",
    "    print('... latitude and longitude extracted for dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load NYC dataframe\n",
    "felony_df = pd.read_csv('NYPD_7_Major_Felony_Incidents.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERROR?: the cleaning function seems to take forever... need to take a closer look/maybe fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ... and clean it\n",
    "#felony_df = cd.clean_NYPD(felony_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... latitude and longitude extracted for dataframe.\n",
      "... latitude and longitude extracted for dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Extact Lattitude and longitude data for both dataframes\n",
    "parse_latlong(school_df, 'latlon')\n",
    "parse_latlong(felony_df, 'Location 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance:  13.120085\n",
      "... w/in 2 mi? False\n",
      "... w/in 50 mi? True\n"
     ]
    }
   ],
   "source": [
    "# Testing vincenty on the first felony and first school\n",
    "first_school_point = (school_df.loc[0,'lat'], school_df.loc[0,'long']) \n",
    "first_felony_point = (felony_df.loc[1,'lat'], felony_df.loc[1,'long']) \n",
    "\n",
    "# not w/in 2 miles, but yes, w/in 50\n",
    "print('Distance: ', vincenty(first_school_point, first_felony_point))\n",
    "print(\"... w/in 2 mi?\", is_in_radius(first_school_point, first_felony_point, 2))\n",
    "print(\"... w/in 50 mi?\",is_in_radius(first_school_point, first_felony_point, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function(s) to extract crime tallies w/in radius of schools\n",
    "\n",
    "I suspect that looping through each school is going to take forever... but we'll try that first and then explore a smarter (dynamic programming) alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... there are 640 missing latlon entries\n",
      "... there are 640 missing lat entries\n"
     ]
    }
   ],
   "source": [
    "# Quick Check, are there rows with 'latlon' but not 'lat'\n",
    "print('... there are {} missing latlon entries'.format(sum(school_df.latlon.isnull())))\n",
    "print('... there are {} missing lat entries'.format(sum(school_df.lat.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BRUTE FORCE OPTION: \n",
    "# This is super inefficient because the function has to apply the location filter over\n",
    "# the entire NYPD df (well, the year subset) for each school & each year.\n",
    "\n",
    "def bf_crimecount(school_df, felony_df, radius = 1):\n",
    "    \"\"\"\n",
    "    Brute force function to find all felonies w/in given radius of each school.\n",
    "    INPUT: school df w/ cols 'latlon', 'lat', 'long', and 'School Year'\n",
    "           felony df w/ cols 'Occurrence Year', 'lat','long','Offense', and 'Identifier'\n",
    "    OUTPUT: n/a, modifies school data.\n",
    "    \"\"\"\n",
    "    # Initialize new columns\n",
    "    school_df['CrimeIDS'] = pd.Series()\n",
    "    school_df['Total Felonies w/in 1mi'] = pd.Series()\n",
    "    school_df['Grand Larceny w/in 1mi'] = pd.Series()\n",
    "    school_df['Robbery w/in 1mi'] = pd.Series()\n",
    "    school_df['Burglary w/in 1mi'] = pd.Series()\n",
    "    school_df['Assault w/in 1mi'] = pd.Series()\n",
    "    school_df['Auto Theft w/in 1mi'] = pd.Series()\n",
    "    school_df['Rape w/in 1mi'] = pd.Series()\n",
    "    school_df['Murders w/in 1mi'] = pd.Series()\n",
    "    print('... created 9 new empty columns to store crime information.') # for debugging\n",
    "    \n",
    "    # Group by location (school) and Year\n",
    "    grouped = school_df[school_df.lat.notnull()].groupby(['latlon','School Year'])\n",
    "    print('... grouped by school and year, {} groups in total'.format(len(grouped.groups))) # for debugging\n",
    "    \n",
    "    # Loop through schools & years\n",
    "    for name, df in grouped:\n",
    "        print('>>> now processing group:', name) # for debugging\n",
    "        coordinates, year = name # unpacking from groupby \n",
    "        location = (df.lat.mean(), df.long.mean())\n",
    "        #NOTE: the coordinates are all the same so the mean is just the location\n",
    "\n",
    "        # get subset of felonies for that year\n",
    "        crimes = felony_df[felony_df['Occurrence Year'] == year] \n",
    "        print('    ... found {} crimes w/in this year'.format(len(crimes))) # for debugging\n",
    "\n",
    "        # further subset felonies using location criteria\n",
    "        if crimes.empty:\n",
    "            local_crimes = pd.DataFrame()\n",
    "        else:    \n",
    "            criteria = crimes.apply(lambda x: is_in_radius(location, (x.lat, x.long), radius), axis=1 )\n",
    "            local_crimes = crimes[criteria]\n",
    "        print('    ... of these, {} occurred w/in one mile'.format(len(local_crimes))) # for debugging\n",
    "        \n",
    "        # compute crime counts\n",
    "        counts = pd.Series({'GRAND LARCENY':0, 'ROBBERY':0, 'BURGLARY':0, 'FELONY ASSAULT':0,\n",
    "                              'RAPE':0, 'GRAND LARCENY OF MOTOR VEHICLE':0,  \n",
    "                              'MURDER & NON-NEGL. MANSLAUGHTE':0})\n",
    "        counts.update(local_crimes['Offense'].value_counts())\n",
    "        \n",
    "        #store crime ids and tallies in school DF\n",
    "        school_df.loc[grouped.groups[name],['CrimeIDS']] = str(local_crimes.Identifier.unique().tolist())\n",
    "        school_df.loc[grouped.groups[name],['Total Felonies w/in 1mi']] = len(local_crimes)        \n",
    "        school_df.loc[grouped.groups[name],['Grand Larceny w/in 1mi']] = counts.loc['GRAND LARCENY']\n",
    "        school_df.loc[grouped.groups[name],['Robbery w/in 1mi']] = counts.loc['ROBBERY']\n",
    "        school_df.loc[grouped.groups[name],['Burglary w/in 1mi']] = counts.loc['BURGLARY']\n",
    "        school_df.loc[grouped.groups[name],['Assault w/in 1mi']] = counts.loc['FELONY ASSAULT']\n",
    "        school_df.loc[grouped.groups[name],['Auto Theft w/in 1mi']] = counts.loc['GRAND LARCENY OF MOTOR VEHICLE']\n",
    "        school_df.loc[grouped.groups[name],['Rape w/in 1mi']] = counts.loc['RAPE']\n",
    "        school_df.loc[grouped.groups[name],['Murder w/in 1mi']] = counts.loc['MURDER & NON-NEGL. MANSLAUGHTE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Brute Force function on a small subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create subsets\n",
    "school_subset = school_df.head(5)\n",
    "felony_subset = felony_df[felony_df['Occurrence Year'] == 2006].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... created 9 new empty columns to store crime information.\n",
      "... grouped by school and year, 4 groups in total\n",
      ">>> now processing group: ('[40.812627, -73.919908]', 2006)\n",
      "    ... found 50 crimes w/in this year\n",
      "    ... of these, 0 occurred w/in one mile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:426: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Murder w/in 1mi'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2f140082fc47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbf_crimecount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschool_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfelony_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-b271e906b034>\u001b[0m in \u001b[0;36mbf_crimecount\u001b[0;34m(school_df, felony_df, radius)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mschool_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Auto Theft w/in 1mi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GRAND LARCENY OF MOTOR VEHICLE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mschool_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rape w/in 1mi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RAPE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mschool_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Murder w/in 1mi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MURDER & NON-NEGL. MANSLAUGHTE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[0;34m(self, key, is_setter)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_setter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                 \u001b[0mkeyidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Murder w/in 1mi'] not in index\""
     ]
    }
   ],
   "source": [
    "# run function\n",
    "bf_crimecount(school_subset, felony_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School Name</th>\n",
       "      <th>School Type</th>\n",
       "      <th>School Year</th>\n",
       "      <th>BEDS Code</th>\n",
       "      <th>County</th>\n",
       "      <th>District</th>\n",
       "      <th>Enrollment</th>\n",
       "      <th>Grade Organization</th>\n",
       "      <th>Need/Resource Category</th>\n",
       "      <th>Alcohol Possession</th>\n",
       "      <th>...</th>\n",
       "      <th>long</th>\n",
       "      <th>CrimeIDS</th>\n",
       "      <th>Total Felonies w/in 1mi</th>\n",
       "      <th>Grand Larceny w/in 1mi</th>\n",
       "      <th>Robbery w/in 1mi</th>\n",
       "      <th>Burglary w/in 1mi</th>\n",
       "      <th>Assault w/in 1mi</th>\n",
       "      <th>Auto Theft w/in 1mi</th>\n",
       "      <th>Rape w/in 1mi</th>\n",
       "      <th>Murders w/in 1mi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bronx Charter School For Better Learning</td>\n",
       "      <td>Charter</td>\n",
       "      <td>2006</td>\n",
       "      <td>321100860855</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.847787</td>\n",
       "      <td>['9fed2cab']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bronx Charter School For Children</td>\n",
       "      <td>Charter</td>\n",
       "      <td>2006</td>\n",
       "      <td>320700860852</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.919908</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bronx Charter School For Excellence</td>\n",
       "      <td>Charter</td>\n",
       "      <td>2006</td>\n",
       "      <td>321100860859</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.858543</td>\n",
       "      <td>['2598f1c7', '26e0d827']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx Charter School For The Arts</td>\n",
       "      <td>Charter</td>\n",
       "      <td>2006</td>\n",
       "      <td>320800860846</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.886463</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bronx Lighthouse Charter School</td>\n",
       "      <td>Charter</td>\n",
       "      <td>2006</td>\n",
       "      <td>320800860870</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                School Name School Type  School Year  \\\n",
       "0  Bronx Charter School For Better Learning     Charter         2006   \n",
       "1         Bronx Charter School For Children     Charter         2006   \n",
       "2       Bronx Charter School For Excellence     Charter         2006   \n",
       "3         Bronx Charter School For The Arts     Charter         2006   \n",
       "4           Bronx Lighthouse Charter School     Charter         2006   \n",
       "\n",
       "      BEDS Code County District Enrollment Grade Organization  \\\n",
       "0  321100860855  Bronx      NaN        229                NaN   \n",
       "1  320700860852  Bronx      NaN        262                NaN   \n",
       "2  321100860859  Bronx      NaN        185                NaN   \n",
       "3  320800860846  Bronx      NaN        284                NaN   \n",
       "4  320800860870  Bronx      NaN        169                NaN   \n",
       "\n",
       "  Need/Resource Category  Alcohol Possession        ...              long  \\\n",
       "0                    NaN                   0        ...        -73.847787   \n",
       "1                    NaN                   0        ...        -73.919908   \n",
       "2                    NaN                   0        ...        -73.858543   \n",
       "3                    NaN                   0        ...        -73.886463   \n",
       "4                    NaN                   0        ...               NaN   \n",
       "\n",
       "                   CrimeIDS  Total Felonies w/in 1mi  Grand Larceny w/in 1mi  \\\n",
       "0              ['9fed2cab']                        1                       0   \n",
       "1                        []                        0                       0   \n",
       "2  ['2598f1c7', '26e0d827']                        2                       1   \n",
       "3                        []                        0                       0   \n",
       "4                       NaN                      NaN                     NaN   \n",
       "\n",
       "   Robbery w/in 1mi  Burglary w/in 1mi  Assault w/in 1mi  Auto Theft w/in 1mi  \\\n",
       "0                 1                  0                 0                    0   \n",
       "1                 0                  0                 0                    0   \n",
       "2                 0                  1                 0                    0   \n",
       "3                 0                  0                 0                    0   \n",
       "4               NaN                NaN               NaN                  NaN   \n",
       "\n",
       "   Rape w/in 1mi  Murders w/in 1mi  \n",
       "0              0               NaN  \n",
       "1              0               NaN  \n",
       "2              0               NaN  \n",
       "3              0               NaN  \n",
       "4            NaN               NaN  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "school_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There must be a smarter way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ???\n",
    "# STEP 1:\n",
    "# STEP 2:\n",
    "# STEP 3:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
