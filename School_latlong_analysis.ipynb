{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lat Long Analysis\n",
    "\n",
    "This portion of our project uses the schools' latitude and longitude (previously obtained using geocoder) to perform some final cleaning on the VADIR data and then join it to the NYC crime data by location. The code below will:  \n",
    "\n",
    "* (A): __Load vadir and felony data__ with the functions from cleandata.py\n",
    "* (B): __Join latlong data__ to the school data frame (using beds/sed code).\n",
    "* (C): __Give schools consistent names__ (we'll use the names from the lat long file)  \n",
    "* (D): __Fill in missing boroughs__ for records from 2006-2007.  \n",
    "* (E): __Identify felonies within a 1 mile__ radius of a given school.  \n",
    "* (F): __Plot correlations__ between school indicents and felonies (by year, by borough, by felony type, by location, by school incident type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from vincenty import vincenty\n",
    "import cleandata as cd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Load data using functions from cleandata.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-72793529d0d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mschool_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_clean_VADIR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfelony_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_clean_NYPD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlatlon_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SchoolLatLon.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#... ??? replace the last call with function call to Aaron's geocoder function???\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mmillervedam/Documents/MIDS/python_bridge_course/INFOW18_FinalProject/cleandata.py\u001b[0m in \u001b[0;36mload_and_clean_VADIR\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# Read in raw data and correct duplicate columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mvadir_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvadir_concat_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAW_DATA_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDUP_COLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# Reorder columns putting demographic information first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cd' is not defined"
     ]
    }
   ],
   "source": [
    "school_df = cd.load_and_clean_VADIR()\n",
    "felony_df = cd.load_and_clean_NYPD()\n",
    "latlon_df = pd.read_csv('SchoolLatLon.csv', index_col=0)\n",
    "#... ??? replace the last call with function call to Aaron's geocoder function???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## B. Join School Data and Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function -- extract lat/long from object type\n",
    "def parse_latlong(dataframe, loc_column):\n",
    "    \"\"\"\n",
    "    Function to extract lat/long coords. \n",
    "    INPUT: dataframe and name of column with string tuple or list pair of coordinates.\n",
    "    OUTPUT: n/a. Function modifies dataframe to add a lat and long column with float type.\n",
    "    \"\"\"\n",
    "    get_lat = lambda x: x.split(',')[0][1:] if type(x)==type('s') else np.nan\n",
    "    get_long = lambda x: x.split(',')[1][:-1] if type(x)==type('s') else np.nan\n",
    "    dataframe['lat'] = dataframe[loc_column].apply(get_lat).astype('float64')\n",
    "    dataframe['long'] = dataframe[loc_column].apply(get_long).astype('float64')\n",
    "    print('... latitude and longitude extracted for dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to add latitude and longitudes to school data frame\n",
    "def join_latlong(school_df, latlon_df, talk=False):\n",
    "    \"\"\"\n",
    "    Function to add (and parse)latitude and longitude \n",
    "    information for each school.\n",
    "    INPUT: school dataframe including \"BEDS Code\" column,\n",
    "           latitude/longitude dataframe w/ \"SED CODE\" col.\n",
    "           (optional 'talk' bool turns on/off print statements)\n",
    "    OUTPUT: dataframe with school data plut new columns \n",
    "            for 'LEGAL NAME', 'Full_Address', 'latlon'(obj),\n",
    "            lat(float64) and long(float64).\n",
    "    \"\"\"\n",
    "    # ensure BEDS and SED are integers so that they'll be recognized as identical\n",
    "    latlon_df[\"SED CODE\"] = latlon_df[\"SED CODE\"].astype(np.int64)\n",
    "    school_df[\"BEDS Code\"] = school_df[\"BEDS Code\"].astype(np.int64)\n",
    "    \n",
    "    # join latlong data to school data using the BEDS code\n",
    "    school_df = pd.merge(school_df, latlon_df, left_on=['BEDS Code'],right_on=['SED CODE'], how='left')\n",
    "    \n",
    "    # parse latlon object in to numerical columns\n",
    "    parse_latlong(school_df, 'latlon')\n",
    "    \n",
    "    # drop the now redundant SED code\n",
    "    school_df.drop(['SED CODE'], axis=1, inplace=True)\n",
    "    \n",
    "    # Take a look at the resulting data/missing values\n",
    "    if talk:\n",
    "        print('... joined df inclues {} unique schools,'.format(len(school_df['BEDS Code'].unique())))\n",
    "        schools_withloc = school_df[school_df['latlon'].notnull()]['BEDS Code'].unique()\n",
    "        schools_missingloc = school_df[school_df['latlon'].isnull()]['BEDS Code'].unique()\n",
    "        print('... of which {} have lat/long'.format(len(schools_withloc)),\n",
    "              'and {} are missing lat/long'.format(len(schools_missingloc)))\n",
    "        \n",
    "    return school_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function Call\n",
    "school_df = join_latlong(school_df, latlon_df, talk=True)\n",
    "\n",
    "# Take a look -- uncomment to run\n",
    "#school_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Fix School Names using info from 'latlon' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def fix_case(x):\n",
    "    \"\"\"Function to put a school name in the correct case\"\"\"\n",
    "    if not x:\n",
    "        return x\n",
    "    elif x[:3] in ['PS ', 'JHS', 'MS ']:\n",
    "        return x[:3] + x[3:].title()\n",
    "    else:\n",
    "        return x.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to eliminate duplicated school names\n",
    "def fix_school_names(school_df, talk=False):\n",
    "    \"\"\" \n",
    "    INPUT: school_df with original 'School Name' column\n",
    "           and with 'LEGAL NAME' column from latlong file.\n",
    "           (optional 'talk' bool turns on/off print statements)\n",
    "    OUTPUT: n/a, fxn modifies school_df to replace duplicate\n",
    "           'School Name's with their (consistent) legal name.\n",
    "    \"\"\"\n",
    "    if talk:\n",
    "        print('... original dataset had {} unique'.format(len(school_df['School Name'].unique())),\n",
    "              'school names but only {} unique BEDS Codes'.format(len(school_df['BEDS Code'].unique())))\n",
    "    \n",
    "    # Fix missing LEGAL NAMES with School Name\n",
    "    school_df['LEGAL NAME'].fillna(school_df['School Name'], inplace=True)\n",
    "    # Fix case and reassign to School Name\n",
    "    school_df['School Name'] = school_df['LEGAL NAME'].apply(fix_case)\n",
    "    # drop the now redundant LEGAL NAME column\n",
    "    school_df.drop(['LEGAL NAME'], axis=1, inplace=True)\n",
    "    \n",
    "    if talk:\n",
    "        print('... new dataset has {} unique school '.format(len(school_df['School Name'].unique())),\n",
    "              'names and {} unique BEDS Codes.'.format(len(school_df['BEDS Code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function call\n",
    "fix_school_names(school_df, talk=True)\n",
    "\n",
    "# Take a look -- uncomment to run\n",
    "#school_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Fill in missing boroughs\n",
    "\n",
    "__TODO:__ From the numbers below it looks like some of the County values got switched around (eg. decrease in Manhattan counts?)... I think we probalby need a way of creating the county_map dictionary that prioritizes the traditional borough name). Come back to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to fill in boroughs\n",
    "def fill_in_boroughs(school_df, talk=False):\n",
    "    \"\"\" \n",
    "    INPUT: school_df with 'County' and 'BEDS Code' columns\n",
    "           (optional 'talk' bool turns on/off print statements)\n",
    "    OUTPUT: n/a, fxn modifies school_df to fill in boroughs.\n",
    "    \"\"\"\n",
    "    if talk:\n",
    "        print('... Originally, {} entries were missing'.format(sum(school_df['County'].isnull())),\n",
    "              ' county info. Other counties:\\n',school_df.County.value_counts())\n",
    "\n",
    "    # create dictionary of county by BEDS Code\n",
    "    c = school_df[school_df['County'].notnull()][['BEDS Code','County']].to_dict()\n",
    "    county_map = {c['BEDS Code'][idx]: c['County'][idx] for idx in c['County'].keys()}\n",
    "    # map counties using dictionary\n",
    "    school_df.County = school_df['BEDS Code'].map(county_map)\n",
    "    \n",
    "    if talk:\n",
    "        print('... Now {} entries are missing'.format(sum(school_df['County'].isnull())),\n",
    "              ' county info. Other counties:\\n',school_df.County.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function call\n",
    "fill_in_boroughs(school_df, talk=True)\n",
    "\n",
    "# Take a look -- uncomment to run\n",
    "#school_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# QUICK CHECK - are any BEDS Codes are linked with more than one Borough(County)?\n",
    "school_df.groupby('BEDS Code')['County'].apply(lambda x: len(x.unique())).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prep NYC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load NYC dataframe\n",
    "felony_df = pd.read_csv('NYPD_7_Major_Felony_Incidents.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ... and clean it   \n",
    "felony_df = cd.clean_NYPD(felony_df)\n",
    "\n",
    "# take a look -- uncomment to run\n",
    "#felony_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visual check that school year column calculation worked\n",
    "felony_df.groupby(['Occurrence Month','Occurrence Year'])['School Year'].mean()['Jun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extact Lattitude and longitude data for felony dataframes\n",
    "parse_latlong(felony_df, 'Location 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E. Extracting crime tallies w/in radius of schools\n",
    "\n",
    "The functions below build together to ultimately 'join' our two datasets by adding columns to the school dataset for tallies of each type of felony that occurred w/in a 1 mile radius. \n",
    "\n",
    "#### Part 1: Distance Calculation using Vincenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick Check, are there rows with 'latlon' but not 'lat'\n",
    "print('... there are {} missing latlon entries'.format(sum(school_df.latlon.isnull())))\n",
    "print('... there are {} missing lat entries'.format(sum(school_df.lat.isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function -- check dist\n",
    "def is_in_radius(school_point, crime_point, radius):\n",
    "    \"\"\"\n",
    "    Function using vincenty package to check distance between school and crime.\n",
    "    INPUT: (lat,long) tuples for school and crime (in degrees), radius in miles.\n",
    "    OUTPUT: Boolean\n",
    "    \"\"\"\n",
    "    return vincenty(school_point, crime_point, miles=True) <= radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing vincenty on the first felony and first school\n",
    "first_school_point = (school_df.loc[0,'lat'], school_df.loc[0,'long']) \n",
    "first_felony_point = (felony_df.loc[1,'lat'], felony_df.loc[1,'long']) \n",
    "\n",
    "# not w/in 2 miles, but yes, w/in 50\n",
    "print('Distance: ', vincenty(first_school_point, first_felony_point))\n",
    "print(\"... w/in 2 mi?\", is_in_radius(first_school_point, first_felony_point, 2))\n",
    "print(\"... w/in 50 mi?\",is_in_radius(first_school_point, first_felony_point, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Setting up a grid for NYC lat/long coords\n",
    "\n",
    "The goal is to use a grid strategy to avoid searching the entire NYC Felony dataframe for each school location (which would take too long).\n",
    "\n",
    "NOTES: The max lat of a school is ~ 40.9  and the distance between 40.9 and 40.95 is over 3 miles... but there are 7 crimes that fell under the jurisdiction of the NY Transit police whose locations are recorded north of 41 degrees (the farthes one is 500 miles away). The minimum longitude of a school is ~-74.24 which is around 3 miles from -74.3. There are 63 crimes that occurred west of -74.3. I suggest that we disregard these outliers for the purposes of our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initial exploration of ranges\n",
    "max_lat = school_df.lat.max()\n",
    "min_lat = school_df.lat.min()\n",
    "max_long = school_df.long.max()\n",
    "min_long = school_df.long.min()\n",
    "\n",
    "lat_dist = vincenty((min_lat, 0.5*(max_long + min_long)),(max_lat, 0.5*(max_long + min_long)), miles=True)\n",
    "long_dist = vincenty((min_long, 0.5*(max_lat + min_lat)),(max_long, 0.5*(max_lat + min_lat)), miles=True)\n",
    "\n",
    "print('Latitude ranges from {} to {} with a total distance of {}'.format(min_lat, max_lat, lat_dist))\n",
    "print('Longitude ranges from {} to {} with a total distance of {}'.format(min_long, max_long, long_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to identify grid cell that contains a given point\n",
    "def nyc_grid(lat,long):\n",
    "    \"\"\"\n",
    "    This function identifies a square mile cell of NYC that contains \n",
    "    the given longitude and latitude point. There are 1500 cells in \n",
    "    total. 30 rows each represent a segement of latitude and 50 \n",
    "    columns each represent a segment of longitude. The cells are \n",
    "    numbered 0 through 1599 and they are unique to this analysis.\n",
    "    \"\"\"\n",
    "    # max and min values from data set\n",
    "    max_lat = 40.95\n",
    "    min_lat = 40.50\n",
    "    max_long = -73.45\n",
    "    min_long = -74.30\n",
    "    \n",
    "    # divide each range into segments of a little over a mile\n",
    "    delta_lat = (max_lat - min_lat)/28\n",
    "    delta_long = (max_long - min_long)/48\n",
    "\n",
    "    # then segment each direction\n",
    "    lat_seg = np.array([min_lat + idx*delta_lat for idx in range(-1,29)])\n",
    "    long_seg = np.array([min_long + idx*delta_long for idx in range(-1,49)])\n",
    "\n",
    "    # identify where given point fits in segments\n",
    "    row = sum(lat_seg <= lat) - 1\n",
    "    col = sum(long_seg <= long) - 1\n",
    "    \n",
    "    # return grid number\n",
    "    if row < 0 or row == 29 or col < 0 or col == 49:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return row * 50 + col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test an out of bound point\n",
    "nyc_grid(40.653161, -76.862164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test an in bound point\n",
    "nyc_grid(40.821798, -73.886463)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Function to find crimes w/in 1 mile of a school\n",
    "\n",
    "STRATEGY: Identify the grid cell containing the school and then search only that cell and its immediately adjacent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper function to get a list of adjacent cells\n",
    "def get_adjacent(cell_num):\n",
    "    \"\"\" \n",
    "    This function identifies a group of cells which together superset \n",
    "    any points within a mile of any location in the original cell.\n",
    "    INPUT: a cell number (< 5999) from NYC grid\n",
    "    OUTPUT: a list of adjacent and or diagonal cell numbers\n",
    "    \n",
    "    NOTE: this function should only be run on cell numbers of vadir\n",
    "    school locations since the nyc_grid is designed so that all\n",
    "    schools are in a cell that is not a boarder cell.\n",
    "    \"\"\"\n",
    "    col = cell_num % 50\n",
    "    row = cell_num // 50\n",
    "    row_range = [row - 1, row, row + 1]\n",
    "    col_range = [col - 1, col, col + 1]\n",
    "    return [r * 50 + c for r in row_range for c in col_range]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test grid adjacency\n",
    "get_adjacent(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to get subset of felonies within a 1 mile radius\n",
    "def get_local_crimes(location, felony_df):\n",
    "    \"\"\"\n",
    "    This function identifies crimes less than 1 mi \n",
    "    from a single school (or GPS location).\n",
    "    INPUT: location (GPS point), felony_df (w/\n",
    "        'NYC_grid column already populated)\n",
    "    OUTPUT: felony_df subset of crimes that \n",
    "        occurred within one mile of school.\n",
    "            \n",
    "    \"\"\"\n",
    "    cells_to_search = get_adjacent(nyc_grid(*location))\n",
    "    \n",
    "    # Get subset of crimes w/in grid\n",
    "    cells_to_search = get_adjacent(nyc_grid(*location)) \n",
    "    crimes = felony_df.loc[felony_df.NYC_grid.isin(cells_to_search)]\n",
    "    \n",
    "    # Further subset by a radius of 1 mile\n",
    "    if not crimes.empty: \n",
    "        r_filter = lambda x: is_in_radius(location,(x.lat,x.long),1)\n",
    "        crimes =  crimes[crimes.apply(r_filter, axis=1)]\n",
    "        \n",
    "    return crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test function on a single school / no crimes\n",
    "this_school = school_df[school_df['BEDS Code'] == 307500014256]\n",
    "location = (this_school.lat.mean(), this_school.long.mean())\n",
    "result = get_local_crimes(location, felony_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now testing on a school with crimes\n",
    "this_school = school_df[school_df['BEDS Code'] == 307500012017]\n",
    "location = (this_school.lat.mean(), this_school.long.mean())\n",
    "result = get_local_crimes(location, felony_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: Crime counting function to search only within adjacent cells of the school\n",
    "\n",
    "NOTE: loading grid cell#s for the felony data set takes 3-4 minutes and only needs to be done once. To skip that step after you've already run this function before simply set the optional parameter skip_gridsetup to True (it defaults False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tally_crime_by_loc(school_df, felony_df, skip_gridsetup = False):\n",
    "    \"\"\"\n",
    "    Function to tally and store information about felonies \n",
    "    that occur w/in one mile of each school in the school_df.\n",
    "    INPUT: school df w/ cols 'latlon', 'lat', 'long', and 'School Year'\n",
    "           felony df w/ cols 'Occurrence Year', 'lat','long','Offense', and 'Identifier'\n",
    "    OUTPUT: n/a, modifies school data.\n",
    "    \"\"\"\n",
    "    if not skip_gridsetup:\n",
    "        # prepare felony dataframe by adding a column for nyc_grid cell number\n",
    "        felony_df.lat.fillna(0, inplace=True)\n",
    "        felony_df.long.fillna(0, inplace=True)\n",
    "        felony_df['NYC_grid'] = felony_df.apply(lambda x: nyc_grid(x.lat, x.long),axis=1)\n",
    "\n",
    "    # Initialize new columns in school data frame\n",
    "    school_df['CrimeIDS'] = pd.Series()\n",
    "    school_df['Total Felonies w/in 1mi'] = pd.Series()\n",
    "    school_df['Grand Larceny w/in 1mi'] = pd.Series()\n",
    "    school_df['Robbery w/in 1mi'] = pd.Series()\n",
    "    school_df['Burglary w/in 1mi'] = pd.Series()\n",
    "    school_df['Assault w/in 1mi'] = pd.Series()\n",
    "    school_df['Auto Theft w/in 1mi'] = pd.Series()\n",
    "    school_df['Rape w/in 1mi'] = pd.Series()\n",
    "    school_df['Murders w/in 1mi'] = pd.Series()\n",
    "    \n",
    "    # Group schools (unique location for each BEDS Code) \n",
    "    grouped = school_df[school_df.lat.notnull()].groupby(['BEDS Code'])\n",
    "    \n",
    "    # Loop through schools, subset crime by location. \n",
    "    for beds, df in grouped:\n",
    "        # NOTE: the coordinates should all be the same so the mean is just the location\n",
    "        assert len(df.lat.unique().tolist()) == 1, 'ERROR: multiple latitudes for this school.'\n",
    "        location = (df.lat.mean(), df.long.mean())\n",
    "        local_crimes = get_local_crimes(location, felony_df)\n",
    "\n",
    "        # tally and store felonies for each year\n",
    "        for year in df['School Year'].unique():\n",
    "            subset = local_crimes[local_crimes['School Year'] == year]\n",
    "            idxs = df[df['School Year'] == year].index.tolist()\n",
    "            school_df.loc[idxs,['CrimeIDS']] = str(subset.Identifier.unique().tolist())\n",
    "            school_df.loc[idxs,['Total Felonies w/in 1mi']] = len(subset)        \n",
    "            school_df.loc[idxs,['Grand Larceny w/in 1mi']] = sum(subset['Offense'] == 'GRAND LARCENY')\n",
    "            school_df.loc[idxs,['Robbery w/in 1mi']] = sum(subset['Offense'] == 'ROBBERY')\n",
    "            school_df.loc[idxs,['Burglary w/in 1mi']] = sum(subset['Offense'] == 'BURGLARY')\n",
    "            school_df.loc[idxs,['Assault w/in 1mi']] = sum(subset['Offense'] == 'FELONY ASSAULT')\n",
    "            school_df.loc[idxs,['Auto Theft w/in 1mi']] = sum(subset['Offense'] == 'GRAND LARCENY OF MOTOR VEHICLE')\n",
    "            school_df.loc[idxs,['Rape w/in 1mi']] = sum(subset['Offense'] == 'RAPE')\n",
    "            school_df.loc[idxs,['Murders w/in 1mi']] = sum(subset['Offense'] == 'MURDER & NON-NEGL. MANSLAUGHTE')\n",
    "\n",
    "    print('... tallied felonies w/in 1 mile of each school.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WARNING ... this cell takes around and hour and half to run (~5 seconds per school)\n",
    "# Try importing: 'vadir_with_felonycounts.csv' for a faster option\n",
    "\n",
    "# run function\n",
    "tally_crime_by_loc(school_df, felony_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.to_csv('vadir_with_felonycounts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shortcut to data - uncomment to run.\n",
    "#school_df = pd.read_csv('vadir_with_felonycounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.groupby('County')['Robbery w/in 1mi','Total Incidents'].mean().plot(kind='bar', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.plot(x='Total Incidents', y='Total Felonies w/in 1mi', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.plot(x='Total Incidents' , y='Burglary w/in 1mi', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.plot(x='Total Incidents' , y='Assault w/in 1mi', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.plot(x='Robbery w/in 1mi' , y='Total Felonies w/in 1mi', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.plot(x='Burglary w/in 1mi' , y='Total Felonies w/in 1mi', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "school_df.plot(x='Grand Larceny w/in 1mi' , y='Total Felonies w/in 1mi', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
